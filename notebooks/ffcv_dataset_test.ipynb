{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from ffcv.fields import RGBImageField\n",
    "from ffcv_pl.generate_dataset import create_beton_wrapper\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyImageLabelDataset(Dataset):\n",
    "\n",
    "    def __init__(self, n_samples: int):\n",
    "        self.samples = [Image.fromarray((np.random.rand(32, 32, 3) * 255).astype('uint8')).convert('RGB')\n",
    "                        for _ in range(n_samples)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.samples[idx], int(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating ffcv dataset into file: ./data/image_label.beton\n",
      "[INFO] number of items: 256\n",
      "[INFO] ffcv fields of items: [<ffcv.fields.rgb_image.RGBImageField object at 0x7f982064ebc0>, <ffcv.fields.basics.IntField object at 0x7f96d4dafe20>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 2549.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Done.\n",
      "##############################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Instantiate the torch dataset that you want to create\n",
    "# Important: the __get_item__ dataset must return tuples! (This depends on FFCV library)\n",
    "image_label_dataset = ToyImageLabelDataset(n_samples=256)\n",
    "\n",
    "# 2. Optional: create Field objects.\n",
    "# here overwrites only RGBImageField, leave default IntField.\n",
    "fields = (RGBImageField(write_mode='jpg', max_resolution=32), None)\n",
    "\n",
    "# 3. call the method, and it will automatically create the .beton dataset for you.\n",
    "create_beton_wrapper(image_label_dataset, \"./data/image_label.beton\", fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torchvision.transforms import RandomHorizontalFlip\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.strategies.ddp import DDPStrategy\n",
    "\n",
    "from ffcv.fields.basics import IntDecoder\n",
    "from ffcv.fields.rgb_image import RandomResizedCropRGBImageDecoder, CenterCropRGBImageDecoder\n",
    "from ffcv.loader import OrderOption\n",
    "from ffcv.transforms import ToTensor, ToTorchImage\n",
    "from ffcv_pl.data_loading import FFCVDataModule\n",
    "from ffcv_pl.ffcv_utils.augmentations import DivideImage255\n",
    "from ffcv_pl.ffcv_utils.utils import FFCVPipelineManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LightningModule\n",
    "class LitAutoEncoder(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(nn.Linear(32 * 32 * 3, 64), nn.ReLU(), nn.Linear(64, 3))\n",
    "        self.decoder = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 32 * 32 * 3))\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        x = batch[0]\n",
    "\n",
    "        b, c, h, w = x.shape\n",
    "        x = x.reshape(b, -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = nn.functional.mse_loss(x_hat, x)\n",
    "\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        pass\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1234\n"
     ]
    }
   ],
   "source": [
    "seed = 1234\n",
    "\n",
    "pl.seed_everything(seed, workers=True)\n",
    "\n",
    "batch_size = 16\n",
    "gpus = 2\n",
    "nodes = 1\n",
    "workers = 8\n",
    "\n",
    "# image label dataset\n",
    "train_manager = FFCVPipelineManager(\n",
    "    \"./data/image_label.beton\",  # previously defined using dataset_creation.py\n",
    "    pipeline_transforms=[\n",
    "        # image pipeline\n",
    "        [RandomResizedCropRGBImageDecoder((32, 32)),\n",
    "        ToTensor(),\n",
    "        ToTorchImage(),\n",
    "        DivideImage255(dtype=torch.float32),\n",
    "        RandomHorizontalFlip(p=0.5)],\n",
    "        # label (int) pipeline\n",
    "        [IntDecoder(),\n",
    "        ToTensor() ]\n",
    "    ],\n",
    "    ordering=OrderOption.RANDOM  # random ordering for training\n",
    ")\n",
    "val_manager = FFCVPipelineManager(\n",
    "    \"./data/image_label.beton\",\n",
    "    pipeline_transforms=[\n",
    "        # image pipeline (different from train)\n",
    "        [CenterCropRGBImageDecoder((32, 32), ratio=1.),\n",
    "        ToTensor(),\n",
    "        ToTorchImage(),\n",
    "        DivideImage255(dtype=torch.float32)],\n",
    "        # label (int) pipeline\n",
    "        None  # if None, uses default\n",
    "    ],\n",
    "    ordering=OrderOption.SEQUENTIAL  # sequential ordering for validation\n",
    ")\n",
    "# datamodule creation\n",
    "# ignore test and predict steps, since managers are not defined.\n",
    "data_module = FFCVDataModule(\n",
    "    batch_size, workers, \n",
    "    train_manager=train_manager, val_manager=val_manager,\n",
    "    is_dist=True, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = LitAutoEncoder()\n",
    "\n",
    "# trainer\n",
    "trainer = pl.Trainer(\n",
    "    # strategy=DDPStrategy(find_unused_parameters=False),\n",
    "    strategy='ddp_notebook',\n",
    "    deterministic=True,\n",
    "    accelerator='gpu',\n",
    "    devices=gpus,\n",
    "    num_nodes=nodes,\n",
    "    max_epochs=5,\n",
    "    logger=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Seed set to 1234\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\n",
      "[rank: 1] Seed set to 1234\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 2 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "ProcessRaisedException",
     "evalue": "\n\n-- Process 1 terminated with the following error:\nTraceback (most recent call last):\n  File \"/root/miniconda3/envs/vqvae/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 74, in _wrap\n    fn(i, *args)\n  File \"/root/miniconda3/envs/vqvae/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py\", line 170, in _wrapping_function\n    results = function(*args, **kwargs)\n  File \"/root/miniconda3/envs/vqvae/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 580, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/root/miniconda3/envs/vqvae/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 947, in _run\n    self.strategy.setup_environment()\n  File \"/root/miniconda3/envs/vqvae/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py\", line 149, in setup_environment\n    super().setup_environment()\n  File \"/root/miniconda3/envs/vqvae/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py\", line 128, in setup_environment\n    self.accelerator.setup_device(self.root_device)\n  File \"/root/miniconda3/envs/vqvae/lib/python3.10/site-packages/pytorch_lightning/accelerators/cuda.py\", line 44, in setup_device\n    _check_cuda_matmul_precision(device)\n  File \"/root/miniconda3/envs/vqvae/lib/python3.10/site-packages/lightning_fabric/accelerators/cuda.py\", line 348, in _check_cuda_matmul_precision\n    major, _ = torch.cuda.get_device_capability(device)\n  File \"/root/miniconda3/envs/vqvae/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 435, in get_device_capability\n    prop = get_device_properties(device)\n  File \"/root/miniconda3/envs/vqvae/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 449, in get_device_properties\n    _lazy_init()  # will define _get_device_properties\n  File \"/root/miniconda3/envs/vqvae/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 284, in _lazy_init\n    raise RuntimeError(\nRuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessRaisedException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# start training!\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/vqvae/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/vqvae/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlauncher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/miniconda3/envs/vqvae/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py:141\u001b[0m, in \u001b[0;36m_MultiProcessingLauncher.launch\u001b[0;34m(self, function, trainer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m process_context \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mstart_processes(\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapping_function,\n\u001b[1;32m    135\u001b[0m     args\u001b[38;5;241m=\u001b[39mprocess_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     join\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# we will join ourselves to get the process references\u001b[39;00m\n\u001b[1;32m    139\u001b[0m )\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocs \u001b[38;5;241m=\u001b[39m process_context\u001b[38;5;241m.\u001b[39mprocesses\n\u001b[0;32m--> 141\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mprocess_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    144\u001b[0m worker_output \u001b[38;5;241m=\u001b[39m return_queue\u001b[38;5;241m.\u001b[39mget()\n",
      "File \u001b[0;32m~/miniconda3/envs/vqvae/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:163\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    161\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-- Process \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with the following error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m error_index\n\u001b[1;32m    162\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m original_trace\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ProcessRaisedException(msg, error_index, failed_process\u001b[38;5;241m.\u001b[39mpid)\n",
      "\u001b[0;31mProcessRaisedException\u001b[0m: \n\n-- Process 1 terminated with the following error:\nTraceback (most recent call last):\n  File \"/root/miniconda3/envs/vqvae/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 74, in _wrap\n    fn(i, *args)\n  File \"/root/miniconda3/envs/vqvae/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py\", line 170, in _wrapping_function\n    results = function(*args, **kwargs)\n  File \"/root/miniconda3/envs/vqvae/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 580, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/root/miniconda3/envs/vqvae/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 947, in _run\n    self.strategy.setup_environment()\n  File \"/root/miniconda3/envs/vqvae/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py\", line 149, in setup_environment\n    super().setup_environment()\n  File \"/root/miniconda3/envs/vqvae/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py\", line 128, in setup_environment\n    self.accelerator.setup_device(self.root_device)\n  File \"/root/miniconda3/envs/vqvae/lib/python3.10/site-packages/pytorch_lightning/accelerators/cuda.py\", line 44, in setup_device\n    _check_cuda_matmul_precision(device)\n  File \"/root/miniconda3/envs/vqvae/lib/python3.10/site-packages/lightning_fabric/accelerators/cuda.py\", line 348, in _check_cuda_matmul_precision\n    major, _ = torch.cuda.get_device_capability(device)\n  File \"/root/miniconda3/envs/vqvae/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 435, in get_device_capability\n    prop = get_device_properties(device)\n  File \"/root/miniconda3/envs/vqvae/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 449, in get_device_properties\n    _lazy_init()  # will define _get_device_properties\n  File \"/root/miniconda3/envs/vqvae/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 284, in _lazy_init\n    raise RuntimeError(\nRuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n"
     ]
    }
   ],
   "source": [
    "# start training!\n",
    "trainer.fit(model, data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vqvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
